{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 773,
   "id": "698f5ecc-b731-4a51-906f-149c6940c352",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "from sklearn.metrics import f1_score, log_loss, accuracy_score\n",
    "\n",
    "# from charset_normalizer import md__mypyc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36e8e341-9c9d-4e68-809d-aac50e1d921c",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e637802-c1a8-4db1-b0da-99ed5054f26d",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1150,
   "id": "de8f9735-a597-4c18-91cf-7a288c26ddf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 30\n",
    "overlap_rate = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1203,
   "id": "d9b929fc-d364-4a2e-b4a4-d1cfff0d9639",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/processed_w30_o9_comp_npeak.csv\n"
     ]
    }
   ],
   "source": [
    "# file_name = f\"./data/processed_w{window_size}_o{str(overlap_rate).replace('0.', '')}_comp.csv\"\n",
    "# file_name = f\"./data/processed_w{window_size}_o{str(overlap_rate).replace('0.', '')}_comp_npeak_allsubject.csv\"\n",
    "file_name = f\"./data/processed_w{window_size}_o{str(overlap_rate).replace('0.', '')}_comp_npeak.csv\"\n",
    "df = pd.read_csv(file_name)\n",
    "print(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1204,
   "id": "ee83e93d-0d6c-4940-a195-0dafff6edd84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BVP_min</th>\n",
       "      <th>BVP_max</th>\n",
       "      <th>BVP_mean</th>\n",
       "      <th>BVP_std</th>\n",
       "      <th>BVP_n_peak</th>\n",
       "      <th>TEMP_min</th>\n",
       "      <th>TEMP_max</th>\n",
       "      <th>TEMP_mean</th>\n",
       "      <th>TEMP_std</th>\n",
       "      <th>labels</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-163.48</td>\n",
       "      <td>141.10</td>\n",
       "      <td>-1.112052</td>\n",
       "      <td>42.527650</td>\n",
       "      <td>1.233333</td>\n",
       "      <td>31.99</td>\n",
       "      <td>32.05</td>\n",
       "      <td>32.019333</td>\n",
       "      <td>0.017404</td>\n",
       "      <td>1</td>\n",
       "      <td>S14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-117.07</td>\n",
       "      <td>126.23</td>\n",
       "      <td>0.054844</td>\n",
       "      <td>38.785298</td>\n",
       "      <td>1.233333</td>\n",
       "      <td>31.99</td>\n",
       "      <td>32.05</td>\n",
       "      <td>32.020417</td>\n",
       "      <td>0.016703</td>\n",
       "      <td>1</td>\n",
       "      <td>S14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-117.07</td>\n",
       "      <td>126.23</td>\n",
       "      <td>0.436318</td>\n",
       "      <td>40.096374</td>\n",
       "      <td>1.200000</td>\n",
       "      <td>31.99</td>\n",
       "      <td>32.05</td>\n",
       "      <td>32.020750</td>\n",
       "      <td>0.016184</td>\n",
       "      <td>1</td>\n",
       "      <td>S14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-117.07</td>\n",
       "      <td>126.23</td>\n",
       "      <td>0.406578</td>\n",
       "      <td>41.129211</td>\n",
       "      <td>1.166667</td>\n",
       "      <td>31.99</td>\n",
       "      <td>32.05</td>\n",
       "      <td>32.021667</td>\n",
       "      <td>0.016550</td>\n",
       "      <td>1</td>\n",
       "      <td>S14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-210.57</td>\n",
       "      <td>170.49</td>\n",
       "      <td>-1.314943</td>\n",
       "      <td>48.216133</td>\n",
       "      <td>1.133333</td>\n",
       "      <td>31.99</td>\n",
       "      <td>32.05</td>\n",
       "      <td>32.021833</td>\n",
       "      <td>0.016732</td>\n",
       "      <td>1</td>\n",
       "      <td>S14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   BVP_min  BVP_max  BVP_mean    BVP_std  BVP_n_peak  TEMP_min  TEMP_max  \\\n",
       "0  -163.48   141.10 -1.112052  42.527650    1.233333     31.99     32.05   \n",
       "1  -117.07   126.23  0.054844  38.785298    1.233333     31.99     32.05   \n",
       "2  -117.07   126.23  0.436318  40.096374    1.200000     31.99     32.05   \n",
       "3  -117.07   126.23  0.406578  41.129211    1.166667     31.99     32.05   \n",
       "4  -210.57   170.49 -1.314943  48.216133    1.133333     31.99     32.05   \n",
       "\n",
       "   TEMP_mean  TEMP_std  labels   id  \n",
       "0  32.019333  0.017404       1  S14  \n",
       "1  32.020417  0.016703       1  S14  \n",
       "2  32.020750  0.016184       1  S14  \n",
       "3  32.021667  0.016550       1  S14  \n",
       "4  32.021833  0.016732       1  S14  "
      ]
     },
     "execution_count": 1204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1205,
   "id": "e94e3b9d-7d77-4973-97f3-4f9f14edb025",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['BVP_min', 'BVP_max', 'BVP_mean', 'BVP_std', 'BVP_n_peak', 'TEMP_min',\n",
       "       'TEMP_max', 'TEMP_mean', 'TEMP_std', 'labels', 'id'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 1205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce61b2c4-b5f3-4988-a1bf-0d75c5f3c8fa",
   "metadata": {},
   "source": [
    "### Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1206,
   "id": "c306b6ed-0c0b-4772-885a-980a239175eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BVP_min</th>\n",
       "      <th>BVP_max</th>\n",
       "      <th>BVP_mean</th>\n",
       "      <th>BVP_std</th>\n",
       "      <th>BVP_n_peak</th>\n",
       "      <th>TEMP_min</th>\n",
       "      <th>TEMP_max</th>\n",
       "      <th>TEMP_mean</th>\n",
       "      <th>TEMP_std</th>\n",
       "      <th>labels</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.850905</td>\n",
       "      <td>0.126835</td>\n",
       "      <td>0.355844</td>\n",
       "      <td>0.218744</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.639423</td>\n",
       "      <td>0.640777</td>\n",
       "      <td>0.641357</td>\n",
       "      <td>0.131661</td>\n",
       "      <td>1</td>\n",
       "      <td>S14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.895131</td>\n",
       "      <td>0.112767</td>\n",
       "      <td>0.474092</td>\n",
       "      <td>0.198177</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.639423</td>\n",
       "      <td>0.640777</td>\n",
       "      <td>0.64162</td>\n",
       "      <td>0.123341</td>\n",
       "      <td>1</td>\n",
       "      <td>S14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.895131</td>\n",
       "      <td>0.112767</td>\n",
       "      <td>0.512748</td>\n",
       "      <td>0.205382</td>\n",
       "      <td>0.175</td>\n",
       "      <td>0.639423</td>\n",
       "      <td>0.640777</td>\n",
       "      <td>0.6417</td>\n",
       "      <td>0.117183</td>\n",
       "      <td>1</td>\n",
       "      <td>S14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.895131</td>\n",
       "      <td>0.112767</td>\n",
       "      <td>0.509734</td>\n",
       "      <td>0.211058</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.639423</td>\n",
       "      <td>0.640777</td>\n",
       "      <td>0.641922</td>\n",
       "      <td>0.121519</td>\n",
       "      <td>1</td>\n",
       "      <td>S14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.806032</td>\n",
       "      <td>0.154642</td>\n",
       "      <td>0.335284</td>\n",
       "      <td>0.250006</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.639423</td>\n",
       "      <td>0.640777</td>\n",
       "      <td>0.641963</td>\n",
       "      <td>0.123689</td>\n",
       "      <td>1</td>\n",
       "      <td>S14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    BVP_min   BVP_max  BVP_mean   BVP_std BVP_n_peak  TEMP_min  TEMP_max  \\\n",
       "0  0.850905  0.126835  0.355844  0.218744        0.2  0.639423  0.640777   \n",
       "1  0.895131  0.112767  0.474092  0.198177        0.2  0.639423  0.640777   \n",
       "2  0.895131  0.112767  0.512748  0.205382      0.175  0.639423  0.640777   \n",
       "3  0.895131  0.112767  0.509734  0.211058       0.15  0.639423  0.640777   \n",
       "4  0.806032  0.154642  0.335284  0.250006      0.125  0.639423  0.640777   \n",
       "\n",
       "  TEMP_mean  TEMP_std labels   id  \n",
       "0  0.641357  0.131661      1  S14  \n",
       "1   0.64162  0.123341      1  S14  \n",
       "2    0.6417  0.117183      1  S14  \n",
       "3  0.641922  0.121519      1  S14  \n",
       "4  0.641963  0.123689      1  S14  "
      ]
     },
     "execution_count": 1206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled = MinMaxScaler().fit_transform(df.drop(['labels', 'id'], axis=1).to_numpy())\n",
    "# fit: Compute the minimum and maximum to be used for later scaling.\n",
    "# transform: Scaling features of X according to feature_range.\n",
    "# fit_transform: fit & transform at the same time \n",
    "# both input/output are numpy arrays, and thus, DataFrame needs to be converted to a NumPy array (by callig to_numpy()) \n",
    "\n",
    "# np.column_stack() is takes a sequence of 1-D or 2-D arrays as input and returns a 2-D array with those arrays stacked as columns.\n",
    "df_scaled = pd.DataFrame(\n",
    "  np.column_stack([scaled, df.loc[:, 'labels'].values, df.loc[:, 'id'].values]),\n",
    "  columns=df.columns\n",
    ")\n",
    "\n",
    "df_scaled.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "217930f4-ddbd-4289-bfab-d961aec911a1",
   "metadata": {},
   "source": [
    "### Combine amusement and baseline conditions to make it non-stress class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1186,
   "id": "4bf3bb2d-7561-4823-a54e-4498f0326dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scaled['labels'] = df_scaled['labels'].replace([1,2,3], [0, 1, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1187,
   "id": "3b61b736-39bb-47ce-a5ec-fbdce03ae380",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scaled_selected  = df_scaled.loc[(df_scaled['id'] == \"S14\") | (df_scaled['id'] == \"S15\") | (df_scaled['id'] == \"S16\") | (df_scaled['id'] == \"S17\")]\n",
    "# df_scaled_selected  = df_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1188,
   "id": "bf2483b7-db07-4555-9eed-097c88d93dad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1574"
      ]
     },
     "execution_count": 1188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_scaled_selected.query('labels == 0'))  # the number of data in negative class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1189,
   "id": "4f978f7f-e8ed-4f68-835c-828374ac2f5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "919"
      ]
     },
     "execution_count": 1189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_scaled_selected.query('labels == 1'))  # the number of data in positive class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1190,
   "id": "592a8889-621f-42ca-8d14-e3e3786ec9ce",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# df_scaled.drop([\"BVP_weight_amp_avg\", \"BVP_weight_energy_avg\", \"BVP_power_entropy\"], axis = 1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ded95d5a-81a6-4160-a1cd-dc2bbf358760",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d004b2e-deb2-467a-ac21-c4f46a0f1855",
   "metadata": {},
   "source": [
    "### Building and training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1191,
   "id": "8972d99e-d419-428f-b40f-958a804dc1a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df_scaled_selected.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1192,
   "id": "d363b6d2-e9f6-4ec2-a9d7-6ecbf7ab9f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "def set_seed(SEED):\n",
    "    os.environ['PYTHONHASHSEED'] = str(SEED)\n",
    "    os.environ['TF_DETERMINISTIC_OPS'] = '1'\n",
    "    random.seed(SEED)\n",
    "    tf.random.set_seed(SEED)\n",
    "    np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1193,
   "id": "46ea2697-3782-47c6-a713-0ec093dcb9a6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LeaveOneGroupOut()\n",
      "Fold 0:\n",
      "  Test group={'S14'}\n",
      "  the number of training data=1874\n",
      "  the number of test data=619\n",
      "Epoch 1/40\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 0.6459 - sparse_categorical_accuracy: 0.6366 - val_loss: 0.6306 - val_sparse_categorical_accuracy: 0.6365\n",
      "Epoch 2/40\n",
      "118/118 [==============================] - 0s 1ms/step - loss: 0.6074 - sparse_categorical_accuracy: 0.6505 - val_loss: 0.5745 - val_sparse_categorical_accuracy: 0.6365\n",
      "Epoch 3/40\n",
      "118/118 [==============================] - 0s 1ms/step - loss: 0.5428 - sparse_categorical_accuracy: 0.7028 - val_loss: 0.5193 - val_sparse_categorical_accuracy: 0.6656\n",
      "Epoch 4/40\n",
      "118/118 [==============================] - 0s 979us/step - loss: 0.4983 - sparse_categorical_accuracy: 0.7748 - val_loss: 0.4698 - val_sparse_categorical_accuracy: 0.7108\n",
      "Epoch 5/40\n",
      "118/118 [==============================] - 0s 950us/step - loss: 0.4712 - sparse_categorical_accuracy: 0.7919 - val_loss: 0.3965 - val_sparse_categorical_accuracy: 0.8401\n",
      "Epoch 6/40\n",
      "118/118 [==============================] - 0s 949us/step - loss: 0.4418 - sparse_categorical_accuracy: 0.8015 - val_loss: 0.3206 - val_sparse_categorical_accuracy: 0.9241\n",
      "Epoch 7/40\n",
      "118/118 [==============================] - 0s 1ms/step - loss: 0.3999 - sparse_categorical_accuracy: 0.8148 - val_loss: 0.2763 - val_sparse_categorical_accuracy: 0.9079\n",
      "Epoch 8/40\n",
      "118/118 [==============================] - 0s 969us/step - loss: 0.3832 - sparse_categorical_accuracy: 0.8308 - val_loss: 0.2257 - val_sparse_categorical_accuracy: 0.9499\n",
      "Epoch 9/40\n",
      "118/118 [==============================] - 0s 1ms/step - loss: 0.3783 - sparse_categorical_accuracy: 0.8239 - val_loss: 0.2025 - val_sparse_categorical_accuracy: 0.9855\n",
      "Epoch 10/40\n",
      "118/118 [==============================] - 0s 1ms/step - loss: 0.3521 - sparse_categorical_accuracy: 0.8383 - val_loss: 0.1816 - val_sparse_categorical_accuracy: 0.9564\n",
      "Epoch 11/40\n",
      "118/118 [==============================] - 0s 951us/step - loss: 0.3428 - sparse_categorical_accuracy: 0.8442 - val_loss: 0.1560 - val_sparse_categorical_accuracy: 0.9806\n",
      "Epoch 12/40\n",
      "118/118 [==============================] - 0s 1ms/step - loss: 0.3342 - sparse_categorical_accuracy: 0.8453 - val_loss: 0.1453 - val_sparse_categorical_accuracy: 0.9855\n",
      "Epoch 13/40\n",
      "118/118 [==============================] - 0s 1ms/step - loss: 0.3201 - sparse_categorical_accuracy: 0.8543 - val_loss: 0.1386 - val_sparse_categorical_accuracy: 0.9612\n",
      "Epoch 14/40\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 0.3237 - sparse_categorical_accuracy: 0.8575 - val_loss: 0.1250 - val_sparse_categorical_accuracy: 0.9822\n",
      "Epoch 15/40\n",
      "118/118 [==============================] - 0s 1ms/step - loss: 0.3087 - sparse_categorical_accuracy: 0.8623 - val_loss: 0.1116 - val_sparse_categorical_accuracy: 0.9855\n",
      "Epoch 16/40\n",
      "118/118 [==============================] - 0s 1ms/step - loss: 0.3084 - sparse_categorical_accuracy: 0.8559 - val_loss: 0.1097 - val_sparse_categorical_accuracy: 0.9952\n",
      "Epoch 17/40\n",
      "118/118 [==============================] - 0s 1ms/step - loss: 0.2948 - sparse_categorical_accuracy: 0.8645 - val_loss: 0.0987 - val_sparse_categorical_accuracy: 0.9822\n",
      "Epoch 18/40\n",
      "118/118 [==============================] - 0s 962us/step - loss: 0.3037 - sparse_categorical_accuracy: 0.8591 - val_loss: 0.0939 - val_sparse_categorical_accuracy: 0.9838\n",
      "Epoch 19/40\n",
      "118/118 [==============================] - 0s 966us/step - loss: 0.2904 - sparse_categorical_accuracy: 0.8693 - val_loss: 0.1061 - val_sparse_categorical_accuracy: 0.9645\n",
      "Epoch 20/40\n",
      "118/118 [==============================] - 0s 994us/step - loss: 0.3062 - sparse_categorical_accuracy: 0.8442 - val_loss: 0.0825 - val_sparse_categorical_accuracy: 0.9903\n",
      "Epoch 21/40\n",
      "118/118 [==============================] - 0s 975us/step - loss: 0.2854 - sparse_categorical_accuracy: 0.8650 - val_loss: 0.0773 - val_sparse_categorical_accuracy: 0.9903\n",
      "Epoch 22/40\n",
      "118/118 [==============================] - 0s 1ms/step - loss: 0.2799 - sparse_categorical_accuracy: 0.8698 - val_loss: 0.0715 - val_sparse_categorical_accuracy: 0.9903\n",
      "Epoch 23/40\n",
      "118/118 [==============================] - 0s 972us/step - loss: 0.2822 - sparse_categorical_accuracy: 0.8698 - val_loss: 0.0679 - val_sparse_categorical_accuracy: 0.9903\n",
      "Epoch 24/40\n",
      "118/118 [==============================] - 0s 975us/step - loss: 0.2752 - sparse_categorical_accuracy: 0.8687 - val_loss: 0.0602 - val_sparse_categorical_accuracy: 0.9919\n",
      "Epoch 25/40\n",
      "118/118 [==============================] - 0s 962us/step - loss: 0.2882 - sparse_categorical_accuracy: 0.8607 - val_loss: 0.0636 - val_sparse_categorical_accuracy: 0.9822\n",
      "Epoch 26/40\n",
      "118/118 [==============================] - 0s 1ms/step - loss: 0.2786 - sparse_categorical_accuracy: 0.8671 - val_loss: 0.0662 - val_sparse_categorical_accuracy: 0.9887\n",
      "Epoch 27/40\n",
      "118/118 [==============================] - 0s 1ms/step - loss: 0.2720 - sparse_categorical_accuracy: 0.8735 - val_loss: 0.0557 - val_sparse_categorical_accuracy: 0.9903\n",
      "Epoch 28/40\n",
      "118/118 [==============================] - 0s 1ms/step - loss: 0.2747 - sparse_categorical_accuracy: 0.8677 - val_loss: 0.0594 - val_sparse_categorical_accuracy: 0.9887\n",
      "Epoch 29/40\n",
      "118/118 [==============================] - 0s 975us/step - loss: 0.2634 - sparse_categorical_accuracy: 0.8725 - val_loss: 0.0670 - val_sparse_categorical_accuracy: 0.9822\n",
      "Epoch 30/40\n",
      "118/118 [==============================] - 0s 1ms/step - loss: 0.2833 - sparse_categorical_accuracy: 0.8623 - val_loss: 0.0572 - val_sparse_categorical_accuracy: 0.9855\n",
      "Epoch 31/40\n",
      "118/118 [==============================] - 0s 1ms/step - loss: 0.2719 - sparse_categorical_accuracy: 0.8773 - val_loss: 0.0567 - val_sparse_categorical_accuracy: 0.9887\n",
      "Epoch 32/40\n",
      "118/118 [==============================] - 0s 985us/step - loss: 0.2648 - sparse_categorical_accuracy: 0.8677 - val_loss: 0.0557 - val_sparse_categorical_accuracy: 0.9887\n",
      "Epoch 33/40\n",
      "118/118 [==============================] - 0s 996us/step - loss: 0.2624 - sparse_categorical_accuracy: 0.8645 - val_loss: 0.0502 - val_sparse_categorical_accuracy: 0.9887\n",
      "Epoch 34/40\n",
      "118/118 [==============================] - 0s 1ms/step - loss: 0.2651 - sparse_categorical_accuracy: 0.8719 - val_loss: 0.0492 - val_sparse_categorical_accuracy: 0.9903\n",
      "Epoch 35/40\n",
      "118/118 [==============================] - 0s 983us/step - loss: 0.2669 - sparse_categorical_accuracy: 0.8655 - val_loss: 0.0508 - val_sparse_categorical_accuracy: 0.9871\n",
      "Epoch 36/40\n",
      "118/118 [==============================] - 0s 975us/step - loss: 0.2581 - sparse_categorical_accuracy: 0.8730 - val_loss: 0.0661 - val_sparse_categorical_accuracy: 0.9742\n",
      "Epoch 37/40\n",
      "118/118 [==============================] - 0s 973us/step - loss: 0.2593 - sparse_categorical_accuracy: 0.8751 - val_loss: 0.0491 - val_sparse_categorical_accuracy: 0.9887\n",
      "Epoch 38/40\n",
      "118/118 [==============================] - 0s 973us/step - loss: 0.2523 - sparse_categorical_accuracy: 0.8741 - val_loss: 0.0515 - val_sparse_categorical_accuracy: 0.9838\n",
      "Epoch 39/40\n",
      "118/118 [==============================] - 0s 973us/step - loss: 0.2562 - sparse_categorical_accuracy: 0.8719 - val_loss: 0.0599 - val_sparse_categorical_accuracy: 0.9822\n",
      "Epoch 40/40\n",
      "118/118 [==============================] - 0s 972us/step - loss: 0.2596 - sparse_categorical_accuracy: 0.8709 - val_loss: 0.0469 - val_sparse_categorical_accuracy: 0.9871\n",
      "{'Loss': 0.04686496080347189, 'Accuracy': 0.9870759289176091, 'F1': 0.9859808850840242}\n",
      "Fold 1:\n",
      "  Test group={'S15'}\n",
      "  the number of training data=1873\n",
      "  the number of test data=620\n",
      "Epoch 1/40\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 0.6445 - sparse_categorical_accuracy: 0.6252 - val_loss: 0.6650 - val_sparse_categorical_accuracy: 0.6323\n",
      "Epoch 2/40\n",
      "118/118 [==============================] - 0s 1ms/step - loss: 0.5514 - sparse_categorical_accuracy: 0.6903 - val_loss: 0.7363 - val_sparse_categorical_accuracy: 0.6323\n",
      "Epoch 3/40\n",
      "118/118 [==============================] - 0s 966us/step - loss: 0.4680 - sparse_categorical_accuracy: 0.7955 - val_loss: 0.8658 - val_sparse_categorical_accuracy: 0.6323\n",
      "Epoch 4/40\n",
      "118/118 [==============================] - 0s 965us/step - loss: 0.3915 - sparse_categorical_accuracy: 0.8660 - val_loss: 1.0155 - val_sparse_categorical_accuracy: 0.6323\n",
      "Epoch 5/40\n",
      "118/118 [==============================] - 0s 969us/step - loss: 0.3187 - sparse_categorical_accuracy: 0.9087 - val_loss: 1.0901 - val_sparse_categorical_accuracy: 0.6323\n",
      "Epoch 6/40\n",
      "118/118 [==============================] - 0s 968us/step - loss: 0.2308 - sparse_categorical_accuracy: 0.9375 - val_loss: 1.0967 - val_sparse_categorical_accuracy: 0.6274\n",
      "Epoch 7/40\n",
      "118/118 [==============================] - 0s 1ms/step - loss: 0.1902 - sparse_categorical_accuracy: 0.9466 - val_loss: 1.2230 - val_sparse_categorical_accuracy: 0.6258\n",
      "Epoch 8/40\n",
      "118/118 [==============================] - 0s 944us/step - loss: 0.1533 - sparse_categorical_accuracy: 0.9637 - val_loss: 1.4208 - val_sparse_categorical_accuracy: 0.6258\n",
      "Epoch 9/40\n",
      "118/118 [==============================] - 0s 966us/step - loss: 0.1415 - sparse_categorical_accuracy: 0.9600 - val_loss: 1.3740 - val_sparse_categorical_accuracy: 0.6226\n",
      "Epoch 10/40\n",
      "118/118 [==============================] - 0s 1ms/step - loss: 0.1202 - sparse_categorical_accuracy: 0.9696 - val_loss: 1.4663 - val_sparse_categorical_accuracy: 0.6242\n",
      "Epoch 11/40\n",
      "118/118 [==============================] - 0s 1ms/step - loss: 0.1173 - sparse_categorical_accuracy: 0.9637 - val_loss: 1.4776 - val_sparse_categorical_accuracy: 0.6226\n",
      "Epoch 12/40\n",
      "118/118 [==============================] - 0s 1ms/step - loss: 0.1102 - sparse_categorical_accuracy: 0.9696 - val_loss: 1.6545 - val_sparse_categorical_accuracy: 0.6242\n",
      "Epoch 13/40\n",
      "118/118 [==============================] - 0s 1ms/step - loss: 0.1015 - sparse_categorical_accuracy: 0.9728 - val_loss: 1.7283 - val_sparse_categorical_accuracy: 0.6242\n",
      "Epoch 14/40\n",
      "118/118 [==============================] - 0s 976us/step - loss: 0.1066 - sparse_categorical_accuracy: 0.9685 - val_loss: 1.6855 - val_sparse_categorical_accuracy: 0.6194\n",
      "Epoch 15/40\n",
      "118/118 [==============================] - 0s 952us/step - loss: 0.0916 - sparse_categorical_accuracy: 0.9733 - val_loss: 1.8261 - val_sparse_categorical_accuracy: 0.6226\n",
      "Epoch 16/40\n",
      "118/118 [==============================] - 0s 957us/step - loss: 0.0959 - sparse_categorical_accuracy: 0.9712 - val_loss: 1.6635 - val_sparse_categorical_accuracy: 0.6161\n",
      "Epoch 17/40\n",
      "118/118 [==============================] - 0s 959us/step - loss: 0.0861 - sparse_categorical_accuracy: 0.9728 - val_loss: 1.7672 - val_sparse_categorical_accuracy: 0.6177\n",
      "Epoch 18/40\n",
      "118/118 [==============================] - 0s 962us/step - loss: 0.0882 - sparse_categorical_accuracy: 0.9765 - val_loss: 1.9988 - val_sparse_categorical_accuracy: 0.6194\n",
      "Epoch 19/40\n",
      "118/118 [==============================] - 0s 962us/step - loss: 0.0741 - sparse_categorical_accuracy: 0.9808 - val_loss: 2.0313 - val_sparse_categorical_accuracy: 0.6210\n",
      "Epoch 20/40\n",
      "118/118 [==============================] - 0s 1ms/step - loss: 0.0806 - sparse_categorical_accuracy: 0.9765 - val_loss: 2.0630 - val_sparse_categorical_accuracy: 0.6194\n",
      "Epoch 21/40\n",
      "118/118 [==============================] - 0s 958us/step - loss: 0.0814 - sparse_categorical_accuracy: 0.9786 - val_loss: 1.9952 - val_sparse_categorical_accuracy: 0.6194\n",
      "Epoch 22/40\n",
      "118/118 [==============================] - 0s 966us/step - loss: 0.0767 - sparse_categorical_accuracy: 0.9765 - val_loss: 2.1844 - val_sparse_categorical_accuracy: 0.6194\n",
      "Epoch 23/40\n",
      "118/118 [==============================] - 0s 978us/step - loss: 0.0783 - sparse_categorical_accuracy: 0.9792 - val_loss: 2.1864 - val_sparse_categorical_accuracy: 0.6210\n",
      "Epoch 24/40\n",
      "118/118 [==============================] - 0s 940us/step - loss: 0.0623 - sparse_categorical_accuracy: 0.9851 - val_loss: 2.3760 - val_sparse_categorical_accuracy: 0.6210\n",
      "Epoch 25/40\n",
      "118/118 [==============================] - 0s 997us/step - loss: 0.0660 - sparse_categorical_accuracy: 0.9808 - val_loss: 2.3228 - val_sparse_categorical_accuracy: 0.6210\n",
      "Epoch 26/40\n",
      "118/118 [==============================] - 0s 957us/step - loss: 0.0658 - sparse_categorical_accuracy: 0.9834 - val_loss: 2.1363 - val_sparse_categorical_accuracy: 0.6097\n",
      "Epoch 27/40\n",
      "118/118 [==============================] - 0s 949us/step - loss: 0.0594 - sparse_categorical_accuracy: 0.9818 - val_loss: 2.2301 - val_sparse_categorical_accuracy: 0.6129\n",
      "Epoch 28/40\n",
      "118/118 [==============================] - 0s 943us/step - loss: 0.0698 - sparse_categorical_accuracy: 0.9813 - val_loss: 2.6008 - val_sparse_categorical_accuracy: 0.6177\n",
      "Epoch 29/40\n",
      "118/118 [==============================] - 0s 960us/step - loss: 0.0643 - sparse_categorical_accuracy: 0.9834 - val_loss: 2.3978 - val_sparse_categorical_accuracy: 0.6194\n",
      "Epoch 30/40\n",
      "118/118 [==============================] - 0s 1ms/step - loss: 0.0643 - sparse_categorical_accuracy: 0.9808 - val_loss: 2.2838 - val_sparse_categorical_accuracy: 0.6161\n",
      "Epoch 31/40\n",
      "118/118 [==============================] - 0s 986us/step - loss: 0.0569 - sparse_categorical_accuracy: 0.9840 - val_loss: 2.4125 - val_sparse_categorical_accuracy: 0.6161\n",
      "Epoch 32/40\n",
      "118/118 [==============================] - 0s 952us/step - loss: 0.0611 - sparse_categorical_accuracy: 0.9808 - val_loss: 2.2761 - val_sparse_categorical_accuracy: 0.6065\n",
      "Epoch 33/40\n",
      "118/118 [==============================] - 0s 960us/step - loss: 0.0664 - sparse_categorical_accuracy: 0.9813 - val_loss: 2.5158 - val_sparse_categorical_accuracy: 0.6194\n",
      "Epoch 34/40\n",
      "118/118 [==============================] - 0s 957us/step - loss: 0.0594 - sparse_categorical_accuracy: 0.9824 - val_loss: 2.5761 - val_sparse_categorical_accuracy: 0.6194\n",
      "Epoch 35/40\n",
      "118/118 [==============================] - 0s 950us/step - loss: 0.0585 - sparse_categorical_accuracy: 0.9840 - val_loss: 2.6583 - val_sparse_categorical_accuracy: 0.6194\n",
      "Epoch 36/40\n",
      "118/118 [==============================] - 0s 962us/step - loss: 0.0649 - sparse_categorical_accuracy: 0.9834 - val_loss: 2.6087 - val_sparse_categorical_accuracy: 0.6161\n",
      "Epoch 37/40\n",
      "118/118 [==============================] - 0s 986us/step - loss: 0.0534 - sparse_categorical_accuracy: 0.9824 - val_loss: 2.4905 - val_sparse_categorical_accuracy: 0.6129\n",
      "Epoch 38/40\n",
      "118/118 [==============================] - 0s 962us/step - loss: 0.0631 - sparse_categorical_accuracy: 0.9792 - val_loss: 2.5190 - val_sparse_categorical_accuracy: 0.6032\n",
      "Epoch 39/40\n",
      "118/118 [==============================] - 0s 1ms/step - loss: 0.0538 - sparse_categorical_accuracy: 0.9845 - val_loss: 2.5408 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 40/40\n",
      "118/118 [==============================] - 0s 1ms/step - loss: 0.0565 - sparse_categorical_accuracy: 0.9867 - val_loss: 2.5471 - val_sparse_categorical_accuracy: 0.6065\n",
      "{'Loss': 2.5303818896219656, 'Accuracy': 0.6064516129032258, 'F1': 0.38876767676767676}\n",
      "Fold 2:\n",
      "  Test group={'S16'}\n",
      "  the number of training data=1874\n",
      "  the number of test data=619\n",
      "Epoch 1/40\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 0.6601 - sparse_categorical_accuracy: 0.6041 - val_loss: 0.6496 - val_sparse_categorical_accuracy: 0.6365\n",
      "Epoch 2/40\n",
      "118/118 [==============================] - 0s 953us/step - loss: 0.6209 - sparse_categorical_accuracy: 0.5939 - val_loss: 0.6251 - val_sparse_categorical_accuracy: 0.6365\n",
      "Epoch 3/40\n",
      "118/118 [==============================] - 0s 1ms/step - loss: 0.5751 - sparse_categorical_accuracy: 0.6617 - val_loss: 0.5570 - val_sparse_categorical_accuracy: 0.6381\n",
      "Epoch 4/40\n",
      "118/118 [==============================] - 0s 970us/step - loss: 0.5299 - sparse_categorical_accuracy: 0.7236 - val_loss: 0.4881 - val_sparse_categorical_accuracy: 0.7447\n",
      "Epoch 5/40\n",
      "118/118 [==============================] - 0s 1ms/step - loss: 0.4816 - sparse_categorical_accuracy: 0.7759 - val_loss: 0.4259 - val_sparse_categorical_accuracy: 0.9386\n",
      "Epoch 6/40\n",
      "118/118 [==============================] - 0s 1ms/step - loss: 0.4370 - sparse_categorical_accuracy: 0.7796 - val_loss: 0.3491 - val_sparse_categorical_accuracy: 0.9515\n",
      "Epoch 7/40\n",
      "118/118 [==============================] - 0s 992us/step - loss: 0.3824 - sparse_categorical_accuracy: 0.8175 - val_loss: 0.3133 - val_sparse_categorical_accuracy: 0.9580\n",
      "Epoch 8/40\n",
      "118/118 [==============================] - 0s 968us/step - loss: 0.3597 - sparse_categorical_accuracy: 0.8234 - val_loss: 0.2883 - val_sparse_categorical_accuracy: 0.9580\n",
      "Epoch 9/40\n",
      "118/118 [==============================] - 0s 966us/step - loss: 0.3420 - sparse_categorical_accuracy: 0.8319 - val_loss: 0.2625 - val_sparse_categorical_accuracy: 0.9628\n",
      "Epoch 10/40\n",
      "118/118 [==============================] - 0s 1ms/step - loss: 0.3189 - sparse_categorical_accuracy: 0.8394 - val_loss: 0.2538 - val_sparse_categorical_accuracy: 0.9677\n",
      "Epoch 11/40\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 0.3108 - sparse_categorical_accuracy: 0.8399 - val_loss: 0.2319 - val_sparse_categorical_accuracy: 0.9693\n",
      "Epoch 12/40\n",
      "118/118 [==============================] - 0s 976us/step - loss: 0.3039 - sparse_categorical_accuracy: 0.8501 - val_loss: 0.2283 - val_sparse_categorical_accuracy: 0.9661\n",
      "Epoch 13/40\n",
      "118/118 [==============================] - 0s 1ms/step - loss: 0.2919 - sparse_categorical_accuracy: 0.8442 - val_loss: 0.2082 - val_sparse_categorical_accuracy: 0.9790\n",
      "Epoch 14/40\n",
      "118/118 [==============================] - 0s 1ms/step - loss: 0.2957 - sparse_categorical_accuracy: 0.8549 - val_loss: 0.2065 - val_sparse_categorical_accuracy: 0.9677\n",
      "Epoch 15/40\n",
      "118/118 [==============================] - 0s 1ms/step - loss: 0.2903 - sparse_categorical_accuracy: 0.8565 - val_loss: 0.1976 - val_sparse_categorical_accuracy: 0.9774\n",
      "Epoch 16/40\n",
      "118/118 [==============================] - 0s 963us/step - loss: 0.2900 - sparse_categorical_accuracy: 0.8549 - val_loss: 0.1886 - val_sparse_categorical_accuracy: 0.9822\n",
      "Epoch 17/40\n",
      "118/118 [==============================] - 0s 984us/step - loss: 0.2708 - sparse_categorical_accuracy: 0.8645 - val_loss: 0.1763 - val_sparse_categorical_accuracy: 0.9806\n",
      "Epoch 18/40\n",
      "118/118 [==============================] - 0s 976us/step - loss: 0.2794 - sparse_categorical_accuracy: 0.8581 - val_loss: 0.1794 - val_sparse_categorical_accuracy: 0.9806\n",
      "Epoch 19/40\n",
      "118/118 [==============================] - 0s 993us/step - loss: 0.2723 - sparse_categorical_accuracy: 0.8597 - val_loss: 0.1848 - val_sparse_categorical_accuracy: 0.9806\n",
      "Epoch 20/40\n",
      "118/118 [==============================] - 0s 972us/step - loss: 0.2909 - sparse_categorical_accuracy: 0.8436 - val_loss: 0.1830 - val_sparse_categorical_accuracy: 0.9822\n",
      "Epoch 21/40\n",
      "118/118 [==============================] - 0s 997us/step - loss: 0.2645 - sparse_categorical_accuracy: 0.8693 - val_loss: 0.1703 - val_sparse_categorical_accuracy: 0.9855\n",
      "Epoch 22/40\n",
      "118/118 [==============================] - 0s 1ms/step - loss: 0.2569 - sparse_categorical_accuracy: 0.8767 - val_loss: 0.1560 - val_sparse_categorical_accuracy: 0.9855\n",
      "Epoch 23/40\n",
      "118/118 [==============================] - 0s 1ms/step - loss: 0.2572 - sparse_categorical_accuracy: 0.8789 - val_loss: 0.1656 - val_sparse_categorical_accuracy: 0.9838\n",
      "Epoch 24/40\n",
      "118/118 [==============================] - 0s 1ms/step - loss: 0.2582 - sparse_categorical_accuracy: 0.8821 - val_loss: 0.1604 - val_sparse_categorical_accuracy: 0.9822\n",
      "Epoch 25/40\n",
      "118/118 [==============================] - 0s 985us/step - loss: 0.2611 - sparse_categorical_accuracy: 0.8773 - val_loss: 0.1503 - val_sparse_categorical_accuracy: 0.9838\n",
      "Epoch 26/40\n",
      "118/118 [==============================] - 0s 986us/step - loss: 0.2501 - sparse_categorical_accuracy: 0.8837 - val_loss: 0.1566 - val_sparse_categorical_accuracy: 0.9855\n",
      "Epoch 27/40\n",
      "118/118 [==============================] - 0s 1ms/step - loss: 0.2510 - sparse_categorical_accuracy: 0.8858 - val_loss: 0.1561 - val_sparse_categorical_accuracy: 0.9855\n",
      "Epoch 28/40\n",
      "118/118 [==============================] - 0s 991us/step - loss: 0.2500 - sparse_categorical_accuracy: 0.8842 - val_loss: 0.1499 - val_sparse_categorical_accuracy: 0.9855\n",
      "Epoch 29/40\n",
      "118/118 [==============================] - 0s 958us/step - loss: 0.2416 - sparse_categorical_accuracy: 0.8847 - val_loss: 0.1434 - val_sparse_categorical_accuracy: 0.9838\n",
      "Epoch 30/40\n",
      "118/118 [==============================] - 0s 1ms/step - loss: 0.2503 - sparse_categorical_accuracy: 0.8853 - val_loss: 0.1502 - val_sparse_categorical_accuracy: 0.9822\n",
      "Epoch 31/40\n",
      "118/118 [==============================] - 0s 971us/step - loss: 0.2377 - sparse_categorical_accuracy: 0.8901 - val_loss: 0.1503 - val_sparse_categorical_accuracy: 0.9887\n",
      "Epoch 32/40\n",
      "118/118 [==============================] - 0s 1ms/step - loss: 0.2465 - sparse_categorical_accuracy: 0.8927 - val_loss: 0.1415 - val_sparse_categorical_accuracy: 0.9855\n",
      "Epoch 33/40\n",
      "118/118 [==============================] - 0s 953us/step - loss: 0.2384 - sparse_categorical_accuracy: 0.8890 - val_loss: 0.1418 - val_sparse_categorical_accuracy: 0.9871\n",
      "Epoch 34/40\n",
      "118/118 [==============================] - 0s 972us/step - loss: 0.2361 - sparse_categorical_accuracy: 0.8874 - val_loss: 0.1341 - val_sparse_categorical_accuracy: 0.9838\n",
      "Epoch 35/40\n",
      "118/118 [==============================] - 0s 960us/step - loss: 0.2423 - sparse_categorical_accuracy: 0.8831 - val_loss: 0.1395 - val_sparse_categorical_accuracy: 0.9838\n",
      "Epoch 36/40\n",
      "118/118 [==============================] - 0s 969us/step - loss: 0.2369 - sparse_categorical_accuracy: 0.8847 - val_loss: 0.1409 - val_sparse_categorical_accuracy: 0.9838\n",
      "Epoch 37/40\n",
      "118/118 [==============================] - 0s 1ms/step - loss: 0.2301 - sparse_categorical_accuracy: 0.8954 - val_loss: 0.1329 - val_sparse_categorical_accuracy: 0.9855\n",
      "Epoch 38/40\n",
      "118/118 [==============================] - 0s 942us/step - loss: 0.2317 - sparse_categorical_accuracy: 0.8933 - val_loss: 0.1316 - val_sparse_categorical_accuracy: 0.9838\n",
      "Epoch 39/40\n",
      "118/118 [==============================] - 0s 964us/step - loss: 0.2283 - sparse_categorical_accuracy: 0.8890 - val_loss: 0.1339 - val_sparse_categorical_accuracy: 0.9838\n",
      "Epoch 40/40\n",
      "118/118 [==============================] - 0s 966us/step - loss: 0.2280 - sparse_categorical_accuracy: 0.8826 - val_loss: 0.1266 - val_sparse_categorical_accuracy: 0.9871\n",
      "{'Loss': 0.12658000446151824, 'Accuracy': 0.9870759289176091, 'F1': 0.9860081374321881}\n",
      "Fold 3:\n",
      "  Test group={'S17'}\n",
      "  the number of training data=1858\n",
      "  the number of test data=635\n",
      "Epoch 1/40\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 0.6786 - sparse_categorical_accuracy: 0.5963 - val_loss: 0.5714 - val_sparse_categorical_accuracy: 0.6205\n",
      "Epoch 2/40\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.6289 - sparse_categorical_accuracy: 0.6286 - val_loss: 0.5431 - val_sparse_categorical_accuracy: 0.6205\n",
      "Epoch 3/40\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.5755 - sparse_categorical_accuracy: 0.6717 - val_loss: 0.4805 - val_sparse_categorical_accuracy: 0.6787\n",
      "Epoch 4/40\n",
      "117/117 [==============================] - 0s 947us/step - loss: 0.5279 - sparse_categorical_accuracy: 0.7282 - val_loss: 0.4353 - val_sparse_categorical_accuracy: 0.7953\n",
      "Epoch 5/40\n",
      "117/117 [==============================] - 0s 968us/step - loss: 0.4900 - sparse_categorical_accuracy: 0.7863 - val_loss: 0.3489 - val_sparse_categorical_accuracy: 0.8961\n",
      "Epoch 6/40\n",
      "117/117 [==============================] - 0s 952us/step - loss: 0.4249 - sparse_categorical_accuracy: 0.8095 - val_loss: 0.2757 - val_sparse_categorical_accuracy: 0.9181\n",
      "Epoch 7/40\n",
      "117/117 [==============================] - 0s 948us/step - loss: 0.3758 - sparse_categorical_accuracy: 0.8380 - val_loss: 0.2309 - val_sparse_categorical_accuracy: 0.9213\n",
      "Epoch 8/40\n",
      "117/117 [==============================] - 0s 972us/step - loss: 0.3609 - sparse_categorical_accuracy: 0.8455 - val_loss: 0.2052 - val_sparse_categorical_accuracy: 0.9323\n",
      "Epoch 9/40\n",
      "117/117 [==============================] - 0s 974us/step - loss: 0.3503 - sparse_categorical_accuracy: 0.8380 - val_loss: 0.1875 - val_sparse_categorical_accuracy: 0.9323\n",
      "Epoch 10/40\n",
      "117/117 [==============================] - 0s 962us/step - loss: 0.3457 - sparse_categorical_accuracy: 0.8439 - val_loss: 0.1825 - val_sparse_categorical_accuracy: 0.9354\n",
      "Epoch 11/40\n",
      "117/117 [==============================] - 0s 961us/step - loss: 0.3319 - sparse_categorical_accuracy: 0.8531 - val_loss: 0.1718 - val_sparse_categorical_accuracy: 0.9480\n",
      "Epoch 12/40\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.3286 - sparse_categorical_accuracy: 0.8563 - val_loss: 0.1675 - val_sparse_categorical_accuracy: 0.9370\n",
      "Epoch 13/40\n",
      "117/117 [==============================] - 0s 986us/step - loss: 0.3111 - sparse_categorical_accuracy: 0.8681 - val_loss: 0.1565 - val_sparse_categorical_accuracy: 0.9386\n",
      "Epoch 14/40\n",
      "117/117 [==============================] - 0s 969us/step - loss: 0.3123 - sparse_categorical_accuracy: 0.8633 - val_loss: 0.1492 - val_sparse_categorical_accuracy: 0.9465\n",
      "Epoch 15/40\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.2835 - sparse_categorical_accuracy: 0.8778 - val_loss: 0.1462 - val_sparse_categorical_accuracy: 0.9402\n",
      "Epoch 16/40\n",
      "117/117 [==============================] - 0s 958us/step - loss: 0.2955 - sparse_categorical_accuracy: 0.8644 - val_loss: 0.1446 - val_sparse_categorical_accuracy: 0.9465\n",
      "Epoch 17/40\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.2910 - sparse_categorical_accuracy: 0.8735 - val_loss: 0.1408 - val_sparse_categorical_accuracy: 0.9480\n",
      "Epoch 18/40\n",
      "117/117 [==============================] - 0s 1000us/step - loss: 0.2871 - sparse_categorical_accuracy: 0.8741 - val_loss: 0.1328 - val_sparse_categorical_accuracy: 0.9496\n",
      "Epoch 19/40\n",
      "117/117 [==============================] - 0s 981us/step - loss: 0.2872 - sparse_categorical_accuracy: 0.8633 - val_loss: 0.1299 - val_sparse_categorical_accuracy: 0.9496\n",
      "Epoch 20/40\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.2778 - sparse_categorical_accuracy: 0.8762 - val_loss: 0.1322 - val_sparse_categorical_accuracy: 0.9480\n",
      "Epoch 21/40\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.2729 - sparse_categorical_accuracy: 0.8714 - val_loss: 0.1253 - val_sparse_categorical_accuracy: 0.9496\n",
      "Epoch 22/40\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.2676 - sparse_categorical_accuracy: 0.8773 - val_loss: 0.1255 - val_sparse_categorical_accuracy: 0.9559\n",
      "Epoch 23/40\n",
      "117/117 [==============================] - 0s 968us/step - loss: 0.2679 - sparse_categorical_accuracy: 0.8778 - val_loss: 0.1245 - val_sparse_categorical_accuracy: 0.9559\n",
      "Epoch 24/40\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.2638 - sparse_categorical_accuracy: 0.8708 - val_loss: 0.1251 - val_sparse_categorical_accuracy: 0.9528\n",
      "Epoch 25/40\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.2608 - sparse_categorical_accuracy: 0.8703 - val_loss: 0.1174 - val_sparse_categorical_accuracy: 0.9543\n",
      "Epoch 26/40\n",
      "117/117 [==============================] - 0s 975us/step - loss: 0.2625 - sparse_categorical_accuracy: 0.8789 - val_loss: 0.1179 - val_sparse_categorical_accuracy: 0.9559\n",
      "Epoch 27/40\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 0.2635 - sparse_categorical_accuracy: 0.8757 - val_loss: 0.1183 - val_sparse_categorical_accuracy: 0.9575\n",
      "Epoch 28/40\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.2470 - sparse_categorical_accuracy: 0.8859 - val_loss: 0.1172 - val_sparse_categorical_accuracy: 0.9622\n",
      "Epoch 29/40\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.2492 - sparse_categorical_accuracy: 0.8816 - val_loss: 0.1187 - val_sparse_categorical_accuracy: 0.9606\n",
      "Epoch 30/40\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.2486 - sparse_categorical_accuracy: 0.8767 - val_loss: 0.1178 - val_sparse_categorical_accuracy: 0.9638\n",
      "Epoch 31/40\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.2416 - sparse_categorical_accuracy: 0.8859 - val_loss: 0.1186 - val_sparse_categorical_accuracy: 0.9638\n",
      "Epoch 32/40\n",
      "117/117 [==============================] - 0s 976us/step - loss: 0.2424 - sparse_categorical_accuracy: 0.8897 - val_loss: 0.1180 - val_sparse_categorical_accuracy: 0.9638\n",
      "Epoch 33/40\n",
      "117/117 [==============================] - 0s 972us/step - loss: 0.2497 - sparse_categorical_accuracy: 0.8784 - val_loss: 0.1162 - val_sparse_categorical_accuracy: 0.9638\n",
      "Epoch 34/40\n",
      "117/117 [==============================] - 0s 964us/step - loss: 0.2411 - sparse_categorical_accuracy: 0.8778 - val_loss: 0.1193 - val_sparse_categorical_accuracy: 0.9638\n",
      "Epoch 35/40\n",
      "117/117 [==============================] - 0s 958us/step - loss: 0.2513 - sparse_categorical_accuracy: 0.8757 - val_loss: 0.1147 - val_sparse_categorical_accuracy: 0.9654\n",
      "Epoch 36/40\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.2452 - sparse_categorical_accuracy: 0.8741 - val_loss: 0.1196 - val_sparse_categorical_accuracy: 0.9622\n",
      "Epoch 37/40\n",
      "117/117 [==============================] - 0s 960us/step - loss: 0.2398 - sparse_categorical_accuracy: 0.8778 - val_loss: 0.1218 - val_sparse_categorical_accuracy: 0.9575\n",
      "Epoch 38/40\n",
      "117/117 [==============================] - 0s 962us/step - loss: 0.2306 - sparse_categorical_accuracy: 0.8854 - val_loss: 0.1238 - val_sparse_categorical_accuracy: 0.9654\n",
      "Epoch 39/40\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.2312 - sparse_categorical_accuracy: 0.8794 - val_loss: 0.1295 - val_sparse_categorical_accuracy: 0.9669\n",
      "Epoch 40/40\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.2208 - sparse_categorical_accuracy: 0.8897 - val_loss: 0.1324 - val_sparse_categorical_accuracy: 0.9654\n",
      "{'Loss': 0.13243633629524734, 'Accuracy': 0.9653543307086614, 'F1': 0.9636106943402518}\n"
     ]
    }
   ],
   "source": [
    "drop_rate = 0.2\n",
    "set_seed(SEED)\n",
    "\n",
    "X = data[:, :-2].astype(float)\n",
    "y = data[:, -2].astype(int)\n",
    "groups = data[:, -1]\n",
    "\n",
    "logo = LeaveOneGroupOut()\n",
    "logo.get_n_splits(X, y, groups)\n",
    "print(logo)\n",
    "\n",
    "splitter = StratifiedKFold(\n",
    "    n_splits=10, # the number of folds.\n",
    "    shuffle=True,  # whether data are shuffled before splitting.\n",
    "    random_state=SEED # a random seed. \n",
    ") \n",
    "\n",
    "\n",
    "models, METRICS = [], []\n",
    "for i, (train_index, test_index) in enumerate(logo.split(X, y, groups)):\n",
    "# for i, (train_index, test_index) in enumerate(splitter.split(X, y)):\n",
    "    print(f\"Fold {i}:\")\n",
    "    print(f\"  Test group={set(groups[test_index])}\")\n",
    "    X_train = X[train_index]\n",
    "    y_train = y[train_index]\n",
    "    X_test = X[test_index]\n",
    "    y_test = y[test_index]\n",
    "    print(f\"  the number of training data={len(y_train)}\")\n",
    "    print(f\"  the number of test data={len(y_test)}\")\n",
    "\n",
    "    \n",
    "    '''------ Begin: Model specification ------'''\n",
    "    model = keras.models.Sequential([\n",
    "        # keras.layers.Dense(\n",
    "        #     units = 32, \n",
    "        #     input_shape = (X.shape[1],),\n",
    "        #     activation=keras.activations.relu,\n",
    "        #     kernel_initializer=keras.initializers.HeNormal(seed=42),\n",
    "        #     # kernel_regularizer='l2'\n",
    "        # ),\n",
    "        keras.layers.Dense(\n",
    "            units = 8, \n",
    "            input_shape = (X.shape[1],),\n",
    "            activation=keras.activations.relu,\n",
    "            kernel_initializer=keras.initializers.HeNormal(seed=42),\n",
    "            # kernel_regularizer='l2'\n",
    "        ),\n",
    "        keras.layers.Dropout(\n",
    "            rate=drop_rate\n",
    "        ), \n",
    "        keras.layers.Dense(\n",
    "            units = 4, \n",
    "            activation=keras.activations.relu,\n",
    "            kernel_initializer=keras.initializers.HeNormal(seed=42),\n",
    "            # kernel_regularizer='l2'\n",
    "        ),\n",
    "        keras.layers.Dropout(\n",
    "            rate=drop_rate\n",
    "        ), \n",
    "        keras.layers.Dense(\n",
    "        units=2, \n",
    "        activation=keras.activations.softmax,\n",
    "        kernel_initializer=keras.initializers.GlorotNormal(seed=42),\n",
    "        # kernel_regularizer='l2'\n",
    "        )\n",
    "    ])\n",
    "    \n",
    "    # print(model.summary())\n",
    "    '''------ End: Model specification ------'''\n",
    "    \n",
    "    '''------ Begin: Model compiling ------'''\n",
    "    model.compile(\n",
    "        # loss=keras.losses.BinaryCrossentropy(from_logits=False),\n",
    "        loss=keras.losses.SparseCategoricalCrossentropy(),\n",
    "        optimizer=keras.optimizers.Adam(),\n",
    "        metrics=[\n",
    "                keras.metrics.SparseCategoricalAccuracy(), \n",
    "                # keras.metrics.BinaryAccuracy(), \n",
    "        ]\n",
    "    )\n",
    "    '''------ End: Model compiling ------'''\n",
    "    \n",
    "    '''------ Begin: Model fitting ------'''\n",
    "    model.fit(\n",
    "        x=X_train,\n",
    "        y=y_train,\n",
    "        batch_size=16,\n",
    "        epochs=40,\n",
    "        validation_data=(X_test, y_test)\n",
    "    )\n",
    "    '''------ End: Model fitting ------'''\n",
    "    y_prob_dnn = model.predict(X_test)\n",
    "    y_pred_dnn = np.argmax(y_prob_dnn, axis=1)\n",
    "\n",
    "    f1 = f1_score(y_true=y_test, y_pred=y_pred_dnn, average='macro')\n",
    "    loss = log_loss(y_true=y_test, y_pred=y_prob_dnn)\n",
    "    accuracy = accuracy_score(y_true=y_test, y_pred=y_pred_dnn)\n",
    "    METRICS.append({\n",
    "        'Loss': loss, # logistic loss\n",
    "        'Accuracy': accuracy, # accuracy\n",
    "        'F1': f1 # F1 score\n",
    "    })\n",
    "    models.append(model)\n",
    "    print(METRICS[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1170,
   "id": "3fa31690-512a-4bee-85c1-10b380e4efa5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_920\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_3072 (Dense)           (None, 8)                 80        \n",
      "_________________________________________________________________\n",
      "dropout_1688 (Dropout)       (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dense_3073 (Dense)           (None, 4)                 36        \n",
      "_________________________________________________________________\n",
      "dropout_1689 (Dropout)       (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_3074 (Dense)           (None, 2)                 10        \n",
      "=================================================================\n",
      "Total params: 126\n",
      "Trainable params: 126\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e42c27a5-1d44-4622-b9ae-06ef397ef157",
   "metadata": {},
   "source": [
    "### Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1194,
   "id": "0f022ac8-e9df-421b-92b2-0ab5bb3c32cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 0.8865, F1: 0.8311\n"
     ]
    }
   ],
   "source": [
    "acc_list, f1_list = [], []\n",
    "for m in METRICS:\n",
    "    acc_list.append(m['Accuracy'])\n",
    "    f1_list.append(m['F1'])\n",
    "print(f\"Acc: {np.mean(acc_list):.4f}, F1: {np.mean(f1_list):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d040693-f22f-4ee3-b492-e772390293ef",
   "metadata": {},
   "source": [
    "### Model selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1195,
   "id": "c7f6c92e-5bcc-4043-81b7-23b2bf3c4a9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "idx_best = np.argmax(acc_list)\n",
    "print(idx_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1196,
   "id": "db7eed59-88c6-49ca-831a-f0f48904337c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 0.9871, F1: 0.9860\n"
     ]
    }
   ],
   "source": [
    "print(f\"Acc: {np.mean(acc_list[idx_best]):.4f}, F1: {np.mean(f1_list[idx_best]):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1197,
   "id": "38cb0c68-b277-49af-a616-c9aeb2b9bb40",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = models[idx_best]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1104,
   "id": "3c6238f5-d101-4327-9e36-400dee325c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_model = models[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1207,
   "id": "80220f7d-a6d2-45a9-a182-c2e430e4d946",
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_model.save('./models/best_model_compact.h5')\n",
    "best_model = tf.keras.models.load_model('./models/best_model_compact.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1208,
   "id": "0f415cf6-49ff-4290-96e4-0ae357f411cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.02631579  0.03703704  0.58133071  0.12671139  3.          0.44444444\n",
      "  0.28169014  4.09854144 14.02933386]\n",
      "[ -11.78947368  -20.59259259 -296.9337571    -2.09010287   -4.7\n",
      "  -13.17777778   -9.8028169  -136.52555059   -9.23057748]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BVP_min</th>\n",
       "      <th>BVP_max</th>\n",
       "      <th>BVP_mean</th>\n",
       "      <th>BVP_std</th>\n",
       "      <th>BVP_peak_f</th>\n",
       "      <th>TEMP_min</th>\n",
       "      <th>TEMP_max</th>\n",
       "      <th>TEMP_mean</th>\n",
       "      <th>TEMP_std</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>485.0</td>\n",
       "      <td>561.0</td>\n",
       "      <td>512.440446</td>\n",
       "      <td>16.848150</td>\n",
       "      <td>1.833333</td>\n",
       "      <td>30.62</td>\n",
       "      <td>36.42</td>\n",
       "      <td>33.554754</td>\n",
       "      <td>0.690338</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>469.0</td>\n",
       "      <td>561.0</td>\n",
       "      <td>512.216929</td>\n",
       "      <td>16.986857</td>\n",
       "      <td>1.800000</td>\n",
       "      <td>31.58</td>\n",
       "      <td>36.42</td>\n",
       "      <td>33.549579</td>\n",
       "      <td>0.685278</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>469.0</td>\n",
       "      <td>561.0</td>\n",
       "      <td>512.220476</td>\n",
       "      <td>17.036637</td>\n",
       "      <td>1.800000</td>\n",
       "      <td>31.58</td>\n",
       "      <td>36.09</td>\n",
       "      <td>33.528728</td>\n",
       "      <td>0.688757</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>469.0</td>\n",
       "      <td>561.0</td>\n",
       "      <td>512.209326</td>\n",
       "      <td>16.850773</td>\n",
       "      <td>1.800000</td>\n",
       "      <td>30.29</td>\n",
       "      <td>36.09</td>\n",
       "      <td>33.515205</td>\n",
       "      <td>0.696816</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>469.0</td>\n",
       "      <td>561.0</td>\n",
       "      <td>512.319818</td>\n",
       "      <td>16.937081</td>\n",
       "      <td>1.800000</td>\n",
       "      <td>30.29</td>\n",
       "      <td>38.03</td>\n",
       "      <td>33.512985</td>\n",
       "      <td>0.695611</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>476.0</td>\n",
       "      <td>573.0</td>\n",
       "      <td>511.658055</td>\n",
       "      <td>22.729420</td>\n",
       "      <td>1.800000</td>\n",
       "      <td>30.94</td>\n",
       "      <td>34.80</td>\n",
       "      <td>33.396084</td>\n",
       "      <td>0.701112</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>454.0</td>\n",
       "      <td>577.0</td>\n",
       "      <td>510.782851</td>\n",
       "      <td>23.189235</td>\n",
       "      <td>1.800000</td>\n",
       "      <td>30.94</td>\n",
       "      <td>36.09</td>\n",
       "      <td>33.400507</td>\n",
       "      <td>0.697915</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>454.0</td>\n",
       "      <td>577.0</td>\n",
       "      <td>511.164300</td>\n",
       "      <td>23.393213</td>\n",
       "      <td>1.800000</td>\n",
       "      <td>30.94</td>\n",
       "      <td>36.09</td>\n",
       "      <td>33.400735</td>\n",
       "      <td>0.699104</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>454.0</td>\n",
       "      <td>577.0</td>\n",
       "      <td>511.197262</td>\n",
       "      <td>23.943366</td>\n",
       "      <td>1.800000</td>\n",
       "      <td>30.94</td>\n",
       "      <td>36.09</td>\n",
       "      <td>33.398144</td>\n",
       "      <td>0.696720</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>454.0</td>\n",
       "      <td>577.0</td>\n",
       "      <td>510.985294</td>\n",
       "      <td>24.386938</td>\n",
       "      <td>1.800000</td>\n",
       "      <td>30.94</td>\n",
       "      <td>36.09</td>\n",
       "      <td>33.410882</td>\n",
       "      <td>0.690889</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>130 rows  10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    BVP_min  BVP_max    BVP_mean    BVP_std  BVP_peak_f  TEMP_min  TEMP_max  \\\n",
       "0     485.0    561.0  512.440446  16.848150    1.833333     30.62     36.42   \n",
       "1     469.0    561.0  512.216929  16.986857    1.800000     31.58     36.42   \n",
       "2     469.0    561.0  512.220476  17.036637    1.800000     31.58     36.09   \n",
       "3     469.0    561.0  512.209326  16.850773    1.800000     30.29     36.09   \n",
       "4     469.0    561.0  512.319818  16.937081    1.800000     30.29     38.03   \n",
       "..      ...      ...         ...        ...         ...       ...       ...   \n",
       "38    476.0    573.0  511.658055  22.729420    1.800000     30.94     34.80   \n",
       "39    454.0    577.0  510.782851  23.189235    1.800000     30.94     36.09   \n",
       "40    454.0    577.0  511.164300  23.393213    1.800000     30.94     36.09   \n",
       "41    454.0    577.0  511.197262  23.943366    1.800000     30.94     36.09   \n",
       "42    454.0    577.0  510.985294  24.386938    1.800000     30.94     36.09   \n",
       "\n",
       "    TEMP_mean  TEMP_std  labels  \n",
       "0   33.554754  0.690338     1.0  \n",
       "1   33.549579  0.685278     1.0  \n",
       "2   33.528728  0.688757     1.0  \n",
       "3   33.515205  0.696816     1.0  \n",
       "4   33.512985  0.695611     1.0  \n",
       "..        ...       ...     ...  \n",
       "38  33.396084  0.701112     0.0  \n",
       "39  33.400507  0.697915     0.0  \n",
       "40  33.400735  0.699104     0.0  \n",
       "41  33.398144  0.696720     0.0  \n",
       "42  33.410882  0.690889     0.0  \n",
       "\n",
       "[130 rows x 10 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 0.8111, F1: 0.8462\n"
     ]
    }
   ],
   "source": [
    "test_stress = pd.read_csv('./data/processed/stress_raw_data.csv').iloc[:, 1:]\n",
    "test_base = pd.read_csv('./data/processed/baseline_raw_data.csv').iloc[:, 1:]\n",
    "\n",
    "test = pd.concat([test_stress, test_base], axis = 0)\n",
    "# test.drop([\"BVP_peak_f\", \"BVP_weight_amp_avg\", \"BVP_weight_energy_avg\", \"BVP_power_entropy\"], axis = 1, inplace=True)\n",
    "# test.drop([\"BVP_n_peak\"], axis = 1, inplace=True)\n",
    "\n",
    "X_test = test.drop(['labels'], axis=1)\n",
    "y_test = test[\"labels\"]\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(X_test)\n",
    "\n",
    "print(scaler.scale_)\n",
    "print(scaler.min_)\n",
    "\n",
    "test_scaled = scaler.transform(X_test)\n",
    "display(pd.DataFrame(data=test))\n",
    "\n",
    "df_test_scaled = pd.DataFrame(\n",
    "  test_scaled,\n",
    "  columns=X_test.columns\n",
    ")\n",
    "\n",
    "y_prob_dnn = best_model.predict(df_test_scaled)\n",
    "y_pred_dnn = np.argmax(y_prob_dnn, axis=1)\n",
    "\n",
    "f1 = f1_score(y_true=y_test, y_pred=y_pred_dnn, average='macro')\n",
    "loss = log_loss(y_true=y_test, y_pred=y_prob_dnn)\n",
    "accuracy = accuracy_score(y_true=y_test, y_pred=y_pred_dnn)\n",
    "\n",
    "print(f\"Acc: {f1:.4f}, F1: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1209,
   "id": "417cdc02-57b8-4606-8c53-696f2a9390a5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     1.0\n",
      "1     1.0\n",
      "2     1.0\n",
      "3     1.0\n",
      "4     1.0\n",
      "     ... \n",
      "38    0.0\n",
      "39    0.0\n",
      "40    0.0\n",
      "41    0.0\n",
      "42    0.0\n",
      "Name: labels, Length: 130, dtype: float64 [1 1 1 1 1 1 1 1 0 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 0 1 1 1 0 0 0 0 1 1 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "print(y_test, y_pred_dnn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba6b68ba-9654-4ca1-80d3-a7c67138634c",
   "metadata": {},
   "source": [
    "# Generate a TensorFlow Lite Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aafc9249-11ad-4a25-9802-34996e6e5038",
   "metadata": {},
   "source": [
    "### Generate Models without Quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1264,
   "id": "589c5ec8-33a4-4c9f-8834-b8d257832a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths to model files\n",
    "import os\n",
    "MODELS_DIR = 'models/'\n",
    "os.path.join(MODELS_DIR)\n",
    "MODEL_TF = MODELS_DIR + 'model.pb'\n",
    "MODEL_NO_QUANT_TFLITE = MODELS_DIR + 'model_no_quant.tflite'\n",
    "MODEL_TFLITE = MODELS_DIR + 'model.tflite'\n",
    "MODEL_TFLITE_MICRO = MODELS_DIR + 'model.cc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1237,
   "id": "4fbb9794-084c-4b9a-8409-d890f01fe65a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpjviqr8m3/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpjviqr8m3/assets\n",
      "2023-06-07 08:08:55.535580: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-06-07 08:08:55.535659: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 1\n",
      "2023-06-07 08:08:55.535704: I tensorflow/core/grappler/clusters/single_machine.cc:357] Starting new session\n",
      "2023-06-07 08:08:55.535972: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-06-07 08:08:55.536061: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-06-07 08:08:55.536139: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-06-07 08:08:55.536248: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-06-07 08:08:55.536330: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-06-07 08:08:55.536384: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 8097 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3080, pci bus id: 0000:01:00.0, compute capability: 8.6\n",
      "2023-06-07 08:08:55.537115: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1137] Optimization results for grappler item: graph_to_optimize\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.003ms.\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.001ms.\n",
      "\n",
      "2023-06-07 08:08:55.552864: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:351] Ignored output_format.\n",
      "2023-06-07 08:08:55.552874: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:354] Ignored drop_control_dependency.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2400"
      ]
     },
     "execution_count": 1237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert the model to the TensorFlow Lite format without quantization\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(best_model)\n",
    "# converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "# converter.target_spec.supported_types = [tf.float16]\n",
    "tflite_no_quant_model = converter.convert()\n",
    "# model_no_quant_tflite = converter.convert()\n",
    "\n",
    "# # Save the model to disk\n",
    "open(MODEL_NO_QUANT_TFLITE, \"wb\").write(tflite_no_quant_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1247,
   "id": "227232e7-9863-458f-98bb-bf929bf36fff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'name': 'dense_2841_input', 'index': 0, 'shape': array([1, 9], dtype=int32), 'shape_signature': array([-1,  9], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}]\n"
     ]
    }
   ],
   "source": [
    "interpreter = tf.lite.Interpreter(model_path = MODEL_NO_QUANT_TFLITE)\n",
    "input_index = interpreter.get_input_details()[0][\"index\"]\n",
    "output_index = interpreter.get_output_details()[0][\"index\"]\n",
    "\n",
    "interpreter.allocate_tensors()\n",
    "print(interpreter.get_input_details())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe36f627-e09f-487a-91cf-4cc2977c203c",
   "metadata": {},
   "source": [
    "### Model size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1220,
   "id": "342dc7ea-2a21-4605-af80-000eb44d0819",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model is 2.38 KB\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "def format_size(variable):\n",
    "    size_in_bytes = sys.getsizeof(variable)\n",
    "    units = [\"B\", \"KB\", \"MB\", \"GB\", \"TB\"]\n",
    "    unit_index = 0\n",
    "    while size_in_bytes >= 1024 and unit_index < len(units) - 1:\n",
    "        size_in_bytes /= 1024.0\n",
    "        unit_index += 1\n",
    "    return \"{:.2f} {}\".format(size_in_bytes, units[unit_index])\n",
    "\n",
    "print(\"Model is {}\".format(format_size(model_no_quant_tflite)))\n",
    "# print(\"Quantized Model is {}\".format(format_size(model_tflite)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81cd995a-9f1d-4b00-96b8-b968c06652c2",
   "metadata": {},
   "source": [
    "### Deploy to a Microcontroller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1243,
   "id": "ddfcf7fe-054a-4335-b0a9-2bfe7ce39124",
   "metadata": {},
   "outputs": [],
   "source": [
    "!xxd -i {MODEL_NO_QUANT_TFLITE} > {MODEL_TFLITE_MICRO}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1248,
   "id": "73cd7e0e-9a19-4414-a739-42d55f6c05e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "REPLACE_TEXT = MODEL_NO_QUANT_TFLITE.replace('/', '_').replace('.', '_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1249,
   "id": "5681fff0-1a8f-406a-96f7-aef9118542f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "!sed -i 's/'{REPLACE_TEXT}'/g_model/g' {MODEL_TFLITE_MICRO}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1265,
   "id": "502f7f15-1a43-4618-b0aa-65bf5581eae5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u0000\u0000\t\u0000\u0000\u0004\t\u0000\u0000\u0000\u0000\u0007\u0000\u0000\u0006\u0000\u0000\u0005\u0000\u0000\u0004\u0000\u0000(\u0004\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000<\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0001\u0000\u0000\u0000\f\n",
      "\u0000\u0000\u0000\f\n",
      "\u0000\u0004\u0000\u0000\u0000\u0000\u0000\f\n",
      "\u0000\u0000\u0000\u0013\u0000\u0000\u0000min_runtime_version\u0000R\u0004\u0000\u0000\u0000\u0010\u0000\u0000\u00001.5.0\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u000f\u0000\u0000\u0000MLIR Converted.\u0000\u0000\u0000\u000e\u0000\u0018\u0000\u0004\u0000\f\n",
      "\u0000\u0010\u0000\u0014\u0000\u000e\u0000\u0000\u0000\u0014\u0000\u0000\u0000@\u0000\u0000\u0000D\u0000\u0000\u0000H\u0000\u0000\u0000X\u0000\u0000\u0000\u000b\n",
      "\u0000\u0000\u0000\u0007\u0000\u0000x\u0007\u0000\u0000\u0006\u0000\u0000d\u0006\u0000\u0000\u0005\u0000\u0000l\u0004\u0000\u0000\u0003\u0000\u0000\u0002\u0000\u0000\u0001\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0001\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0001\u0000\u0000\u0000\n",
      "\u0000\u0000\u0000\u0004\u0000\u0000\u0000H\u0002\u0000\u0000d\u0001\u0000\u0000\u0000\u0000\u0000\u001c\n",
      "\u0000\u0000\u0000\u0004\u0000\u0000\u0000main\u0000\u0000\u000e\u0000\u0018\u0000\f\n",
      "\u0000\u0010\u0000\u0007\u0000\u0014\u0000\u000e\u0000\u0000\u0000\u0000\u0000\u0000\t\u0001\u0000\u0000\u0000\u001c\n",
      "\u0000\u0000\u0000\u0010\u0000\u0000\u0000\u0004\u0000\u0000\u0000.\u0000\u0000?\u0001\u0000\u0000\u0000\n",
      "\u0000\u0000\u0000\u0001\u0000\u0000\u0000\t\u0000\u0000\u0000\u0019\u0000\u0000\u0000\u0000\u0000\u0000\u0019\u0001\u0000\u0000\u0000\u0014\u0000\u0000\u0000\u000b\n",
      "\u0000\u0000\u0000\u0018\u0000\u0000\u00000\u0000\u0000\u0000 \u0000\u0000\u0000\u0002\u0000\u0000\u0000\u0001\u0000\u0000\u0000\u0002\u0000\u0000\u0000\u0000\u0000Identity\u0000\u0000\u0000\u0000\u0002\u0000\u0000\u0000\u0002\u0000\u0000\u0000R\u0000\u0000\u0018\u0000\u0000\u0000\f\n",
      "\u0000\u0000\u0000\u0004\u0000\u0000\u0000\u0001\u0000\u0000\u0000\t\u0000\u0000\u0000\u0003\u0000\u0000\u0000\u0000\u0000\u0006\u0000\u0000\u0000\u0001\u0000\u0000\u0000@\u0014\u0000\u0000\u0000\n",
      "\u0000\u0000\u0000\u0018\u0000\u0000\u0000h\u0000\u0000\u0000X\u0000\u0000\u0000\u0002\u0000\u0000\u0000\u0001\u0000\u0000\u0000\u0002\u0000\u0000\u0000B\u0000\u0000\u0000sequential_843/dense_2843/MatMul;sequential_843/dense_2843/BiasAdd\u0000\u0000\u0002\u0000\u0000\u0000\u0002\u0000\u0000\u0000L\u0000\u0000\u000e\u0000\u0014\u0000\u0000\u0000\f\n",
      "\u0000\u0007\u0000\u0010\u0000\u000e\u0000\u0000\u0000\u0000\u0000\u001c\n",
      "\u0000\u0000\u0000\u0010\u0000\u0000\u0000\u0004\u0000\u0000\u0000\u001e\n",
      "\u0000\u0000\u0000\u0001\u0001\u0000\u0000\u0000\u0000\u0000\u0003\u0000\u0000\u0000\u0007\u0000\u0000\u0000\u0005\u0000\u0000\u0000\u0002\u0000\u0000\u0000\u0000\u0014\u0000\u0000\u0000\t\u0000\u0000\u0000\u0018\u0000\u0000\u0000\u0000\u0000\u0000x\u0000\u0000\u0000\u0002\u0000\u0000\u0000\u0001\u0000\u0000\u0000\u0004\u0000\u0000\u0000a\u0000\u0000\u0000sequential_843/dense_2842/MatMul;sequential_843/dense_2842/Relu;sequential_843/dense_2842/BiasAdd\u0000\u0000\u0000\u0002\u0000\u0000\u0000\u0004\u0000\u0000\u0000,\u0000\u0000\u000e\u0000\u0016\u0000\u0000\u0000\f\n",
      "\u0000\u0007\u0000\u0010\u0000\u000e\u0000\u0000\u0000\u0000\u0000$\u0000\u0000\u0000\u0018\u0000\u0000\u0000\f\n",
      "\u0000\u0000\u0000\u0000\u0000\u0006\u0000\u0007\u0000\u0006\u0000\u0000\u0000\u0000\u0000\u0000\u0001\u0001\u0000\u0000\u0000\u0007\u0000\u0000\u0000\u0003\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0004\u0000\u0000\u0000\u0003\u0000\u0000\u0000\f\n",
      "\u0000\u0010\u0000\u000b\n",
      "\u0000\u0000\u0000\f\n",
      "\u0000\u0004\u0000\f\n",
      "\u0000\u0000\u0000\t\u0000\u0000\u0000\u0000\u0000\u0000\t\u0001\u0000\u0000\u0000\u0004\u0014\u0000\u0000\u0000\u0000\u0000\u0018\u0000\u0000\u0000\u0000\u0000\u0000x\u0000\u0000\u0000\u0002\u0000\u0000\u0000\u0001\u0000\u0000\u0000\u0000\u0000a\u0000\u0000\u0000sequential_843/dense_2841/MatMul;sequential_843/dense_2841/Relu;sequential_843/dense_2841/BiasAdd\u0000\u0000\u0000\u0002\u0000\u0000\u0000\u0000\u0000\u0000<*\u0004\u0000\u0000\u0000 \u0000\u0000\u00006\u0013?\u0002=p\u001br\u00162?\u0003#?\u0002,?[K:\u0010\u0000\u0000\u0000\u0007\u0000\u0000\u0000\u0014\u0000\u0000\u00008\u0000\u0000\u0000\u0002\u0000\u0000\u0000\u0002\u0000\u0000\u0000\u0004\u0000\u0000\u0000 \u0000\u0000\u0000sequential_843/dense_2843/MatMul\u0000\u0000\u0000\u0000\u0004\u0000\u0000\u0000\u0000\u0000\u0000>(?/\u0019 ?\u0004>0?]?y?Ea\u001c\n",
      "\"?C\u001fxd\f\n",
      "D\u000b\n",
      "\u0015/\u0016K\u0001?;et2\u0013B+\t\u0005G?Us-?\u00063_?S[\u0005?\u0011\u0005@{`??\u0012\u0010\u0000\u0000\u0000\u0006\u0000\u0000\u0000\u0014\u0000\u0000\u00008\u0000\u0000\u0000\u0002\u0000\u0000\u0000\u0004\u0000\u0000\u0000\u0000\u0000 \u0000\u0000\u0000sequential_843/dense_2842/MatMul\u0000\u0000\u0000\u0000z\u0004\u0000\u0000\u0000 \u0001\u0000\u0000>ki\n",
      ">\u0003?>\u0006)'Fv,>=^4G6?\\/\u001c\n",
      ">\t\n",
      "D\u0001\u00039?0?>Eo<\u001d\n",
      "($>\u001c\n",
      "\u0013=*P<$?pSm/;?=|j\u001f>>P>a@\u001e\n",
      ",c=>~N?>.\u0013G\u001f?\u001d\n",
      "HN>3\u00139\u0019bf?z\u0003>~/v9\tu\u0006tW>M&>G?A=TN>b\u0006\u001d\n",
      "\u00188/\u001c\n",
      "0>K.>\u000eL?)^r<5>\u0012>q\u001e\n",
      "-oj>>O}j\u0010\u0000\u0000\u0000\u0005\u0000\u0000\u0000\u0014\u0000\u0000\u00008\u0000\u0000\u0000\u0002\u0000\u0000\u0000\u0000\u0000\t\u0000\u0000\u0000 \u0000\u0000\u0000sequential_843/dense_2841/MatMul\u0000\u0000\u0000\u0000\u0004\u0004\u0000\u0000\u0000 \u0000\u0000\u0000T}>nk>B;z>oP**>nEx=\u0002\u0010\u0000\u0000\u0000\u0004\u0000\u0000\u0000\u0010\u0000\u0000\u0000L\u0000\u0000\u0000\u0001\u0000\u0000\u0000\u0000\u00009\u0000\u0000\u0000sequential_843/dense_2841/BiasAdd/ReadVariableOp/resource\u0000\u0000\u0000~\u0004\u0000\u0000\u0000\u0010\u0000\u0000\u0000\u001d\n",
      ":\">\u0003=>&\u0012~\u0010\u0000\u0000\u0000\u0003\u0000\u0000\u0000\u0010\u0000\u0000\u0000P\u0000\u0000\u0000\u0001\u0000\u0000\u0000\u0004\u0000\u0000\u00009\u0000\u0000\u0000sequential_843/dense_2842/BiasAdd/ReadVariableOp/resource\u0000\u0000\u0000\u0004\u0000\u0006\u0000\u0004\u0000\u0000\u0000\u0000\u0000\u0006\u0000\u0004\u0000\u0006\u0000\u0000\u0000\u0004\u0000\u0000\u0000\u0000\u0000[P$P;\u0000\u0000\u000e\u0000\u0014\u0000\u0004\u0000\u0000\u0000\f\n",
      "\u0000\u0010\u0000\u000e\u0000\u0000\u0000\u0010\u0000\u0000\u0000\u0002\u0000\u0000\u0000\u0010\u0000\u0000\u0000L\u0000\u0000\u0000\u0001\u0000\u0000\u0000\u0002\u0000\u0000\u00009\u0000\u0000\u0000sequential_843/dense_2843/BiasAdd/ReadVariableOp/resource\u0000\u0000\u0000\u0014\u0000\u0018\u0000\u0004\u0000\u0000\u0000\f\n",
      "\u0000\u0010\u0000\u0000\u0000\u0000\u0000\u0014\u0000\u0014\u0000\u0000\u0000\u0014\u0000\u0000\u0000\u0001\u0000\u0000\u0000\u0018\u0000\u0000\u00008\u0000\u0000\u0000(\u0000\u0000\u0000\u0002\u0000\u0000\u0000\u0001\u0000\u0000\u0000\t\u0000\u0000\u0000\u0010\u0000\u0000\u0000dense_2841_input\u0000\u0000\u0000\u0000\u0002\u0000\u0000\u0000\t\u0000\u0000\u0000\u0004\u0000\u0004\u0000\u0004\u0000\u0000\u0000"
     ]
    }
   ],
   "source": [
    "!cat {MODEL_NO_QUANT_TFLITE}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39e32995-5320-490b-b42a-fed981dd93ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b720822e-6c41-498f-a31b-5667e3091655",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cd6ff55-5dad-4d19-b855-feb40630570d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3a4cb9a-3c3f-4931-8a7a-184862dbb90e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b2926f9-59c5-4d87-8c59-2af900e6725d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "12c278b273408fe5cc79043652af9bf73d5ce5d13b4078dc4cb7a3935a8c5e04"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
